{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import Dice\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.utilities.types import TRAIN_DATALOADERS, EVAL_DATALOADERS\n",
    "from lightning.pytorch.loggers import WandbLogger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary_mask_images(img_name, mask_rle, save_path):\n",
    "    img = cv2.imread(os.path.join(\"data/train_img\", img_name))\n",
    "    img = rle_decode(mask_rle, (img.shape[0], img.shape[1]))\n",
    "    cv2.imwrite(os.path.join(save_path, img_name), img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "mask_path = \"data/train_mask\"\n",
    "os.makedirs(mask_path, exist_ok=True)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    img_name = row[\"img_path\"].split('/')[-1]\n",
    "    mask_rle = row[\"mask_rle\"]\n",
    "    \n",
    "    make_binary_mask_images(img_name, mask_rle, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation offline augmentation\n",
    "crop with (256 * 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5712\n",
      "1428\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop_img(img, img_size=256):\n",
    "    img_list = []\n",
    "    \n",
    "    y_cnt = 0\n",
    "    while True:\n",
    "        start_y = y_cnt * img_size\n",
    "        end_y = (y_cnt + 1) * img_size\n",
    "        \n",
    "        if end_y > 1024:\n",
    "            break\n",
    "        \n",
    "        x_cnt = 0\n",
    "        while True:\n",
    "            start_x = x_cnt * img_size\n",
    "            end_x = (x_cnt + 1) * img_size\n",
    "            \n",
    "            if end_x > 1024:\n",
    "                break\n",
    "            \n",
    "            temp_img = img[start_x:end_x, start_y:end_y, :]\n",
    "            x_cnt += 1\n",
    "            img_list.append(temp_img)\n",
    "            \n",
    "        y_cnt += 1\n",
    "\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_list = []\n",
    "for idx, row in val_df.iterrows():\n",
    "    img_name = row[\"img_path\"].split(\"/\")[-1]\n",
    "    img_path = os.path.join(\"data/train_img\", img_name)\n",
    "    mask_path = os.path.join(\"data/train_mask\", img_name)\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    mask = cv2.imread(mask_path)\n",
    "    \n",
    "    images = crop_img(img)\n",
    "    masks = crop_img(mask)\n",
    "    \n",
    "    for idx, (img, mask) in enumerate(zip(images, masks)):\n",
    "        new_img_name = img_name[:-4] + \"_\" + str(idx).zfill(2) + \".png\"\n",
    "        new_data_list.append({\"img_id\": new_img_name[:-4]})\n",
    "        \n",
    "        cv2.imwrite(os.path.join(\"data/train_img\", new_img_name), img)\n",
    "        cv2.imwrite(os.path.join(\"data/train_mask\", new_img_name), mask)\n",
    "\n",
    "    os.remove(img_path)\n",
    "    os.remove(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_4972_00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_4972_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_4972_02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_4972_03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_4972_04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22843</th>\n",
       "      <td>TRAIN_0346_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22844</th>\n",
       "      <td>TRAIN_0346_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22845</th>\n",
       "      <td>TRAIN_0346_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22846</th>\n",
       "      <td>TRAIN_0346_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22847</th>\n",
       "      <td>TRAIN_0346_15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22848 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_id\n",
       "0      TRAIN_4972_00\n",
       "1      TRAIN_4972_01\n",
       "2      TRAIN_4972_02\n",
       "3      TRAIN_4972_03\n",
       "4      TRAIN_4972_04\n",
       "...              ...\n",
       "22843  TRAIN_0346_11\n",
       "22844  TRAIN_0346_12\n",
       "22845  TRAIN_0346_13\n",
       "22846  TRAIN_0346_14\n",
       "22847  TRAIN_0346_15\n",
       "\n",
       "[22848 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val_df = pd.DataFrame(new_data_list)\n",
    "new_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"data/new_train.csv\")\n",
    "new_val_df.to_csv(\"data/new_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"model\": {\n",
    "        \"encoder_name\": \"timm-regnety_320\",\n",
    "        \"encoder_weights\": \"imagenet\",\n",
    "        \"in_channels\": 3,\n",
    "        \"classes\": 1\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"root\": \"data\",\n",
    "        \"batch_size\": 64\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultTransforms:\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def train_transform(self):\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.OneOf(\n",
    "                    [\n",
    "                        A.RandomBrightness(p=1),\n",
    "                        A.RandomBrightnessContrast(p=1),\n",
    "                        A.Emboss(p=1),\n",
    "                        A.RandomShadow(p=1),\n",
    "                        A.NoOp(),\n",
    "                    ],\n",
    "                    p=1,\n",
    "                ),\n",
    "                A.OneOf(\n",
    "                    [\n",
    "                        A.Blur(p=1),\n",
    "                        A.AdvancedBlur(p=1),\n",
    "                        A.MotionBlur(p=1),\n",
    "                    ],\n",
    "                    p=0.6,\n",
    "                ),\n",
    "                A.OneOf(\n",
    "                    [\n",
    "                        A.NoOp(),\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.VerticalFlip(p=0.5),\n",
    "                        A.ShiftScaleRotate(p=0.5),\n",
    "                        A.Rotate(limit=90, p=1, border_mode=cv2.BORDER_REPLICATE),\n",
    "                        A.RandomRotate90(p=1)\n",
    "                    ],\n",
    "                    p=1,\n",
    "                ),\n",
    "                A.RandomCrop(224, 224),\n",
    "                A.Normalize(),\n",
    "                ToTensorV2(transpose_mask=True)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def val_transform(self):\n",
    "        return A.Compose(\n",
    "            [   \n",
    "                A.Resize(224, 224),\n",
    "                A.Normalize(),\n",
    "                ToTensorV2(transpose_mask=True)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def test_transform(self):\n",
    "        return A.Compose(\n",
    "            [\n",
    "                A.Normalize(),\n",
    "                ToTensorV2(transpose_mask=True)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, root, df, train=True, transform=None):\n",
    "        self.root = root\n",
    "        self.data = df\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx, 1]\n",
    "\n",
    "        if self.train:\n",
    "            image = cv2.imread(os.path.join(self.root, \"train_img\", img_name + \".png\"))\n",
    "            mask = cv2.imread(os.path.join(self.root, \"train_mask\", img_name + \".png\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image, mask=mask)\n",
    "                image = augmented['image']\n",
    "                mask = augmented['mask']\n",
    "\n",
    "            return image, mask\n",
    "        else: \n",
    "            image = cv2.imread(os.path.join(self.root, \"test_img\", img_name, + \".png\"))\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "    \n",
    "    \n",
    "class SatelliteDataModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        batch_size: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.transforms = DefaultTransforms()\n",
    "        self.train_transform = self.transforms.train_transform()\n",
    "        self.val_transform = self.transforms.val_transform()\n",
    "        self.test_transform = self.transforms.test_transform()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def setup(self, stage: str) -> None:\n",
    "        train_df = pd.read_csv(os.path.join(self.root, \"new_train.csv\"))\n",
    "        test_df = pd.read_csv(os.path.join(self.root, \"test.csv\"))\n",
    "        val_df = pd.read_csv(os.path.join(self.root, \"new_val.csv\"))\n",
    "        \n",
    "        self.train_dataset = SatelliteDataset(\n",
    "            self.root, df=train_df, train=True, transform=self.train_transform\n",
    "        )\n",
    "        self.val_dataset = SatelliteDataset(\n",
    "            self.root, df=val_df, train=True, transform=self.val_transform\n",
    "        )\n",
    "        self.test_dataset = SatelliteDataset(\n",
    "            self.root, df=test_df, train=False, transform=self.test_transform\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=8\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(\n",
    "            self.test_dataset, batch_size=100, shuffle=False, num_workers=8\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMP(nn.Module):\n",
    "    def __init__(self, encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = smp.UnetPlusPlus(\n",
    "            encoder_name=encoder_name,   \n",
    "            encoder_weights=encoder_weights,   \n",
    "            in_channels=in_channels,             \n",
    "            classes=classes,                    \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        inputs = F.sigmoid(inputs) # sigmoid를 통과한 출력이면 주석처리\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LitSeg(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"net\", \"loss_module\", \"metric_module\"])\n",
    "\n",
    "        self.net = SMP(\n",
    "            encoder_name=configs[\"model\"][\"encoder_name\"], \n",
    "            encoder_weights=configs[\"model\"][\"encoder_weights\"], \n",
    "            in_channels=configs[\"model\"][\"in_channels\"], \n",
    "            classes=configs[\"model\"][\"classes\"], \n",
    "        )\n",
    "\n",
    "        self.loss_module = DiceLoss()\n",
    "        self.metric_module = Dice()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=300)\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, mask = batch\n",
    "        pred = self(img)\n",
    "\n",
    "        loss = self.loss_module(pred, mask)\n",
    "        self.log(\"train/loss\", loss.item())\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img, mask = batch\n",
    "        pred = self(img).squeeze()\n",
    "\n",
    "        loss = self.loss_module(pred, mask)\n",
    "        self.log(\"val/loss\", loss.item(), on_epoch=True, on_step=False)\n",
    "\n",
    "        dice_score = self.metric_module(pred, mask)\n",
    "        self.log(\"val/dice_score\", dice_score, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        \n",
    "        self.logger.log_image(\n",
    "            key=\"results\",\n",
    "            images=[img.unbind(dim=0)[0], pred.unbind(dim=0)[0], mask.float().unbind(dim=0)[0]],\n",
    "            caption=[\"image\", \"pred\", \"mask\"]\n",
    "        )\n",
    "        \n",
    "    def on_test_start(self):\n",
    "        self.result = []\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        img = batch\n",
    "        pred = self(img)\n",
    "        \n",
    "        pred = torch.sigmoid(pred).cpu().numpy()\n",
    "        pred = np.squeeze(pred, axis=1)\n",
    "        pred = (pred > 0.35).astype(np.uint8) # Threshold = 0.35\n",
    "        \n",
    "        for i in range(len(img)):\n",
    "            mask_rle = self.rle_encode(masks[i])\n",
    "            if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n",
    "                self.result.append(-1)\n",
    "            else:\n",
    "                self.result.append(mask_rle)\n",
    "        \n",
    "    def on_test_end(self):\n",
    "        submit = pd.read_csv('data/sample_submission.csv')\n",
    "        submit['mask_rle'] = self.result\n",
    "        submit.to_csv('./submit.csv', index=False)\n",
    "        \n",
    "    def rle_encode(self, mask):\n",
    "        pixels = mask.flatten()\n",
    "        pixels = np.concatenate([[0], pixels, [0]])\n",
    "        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "        runs[1::2] -= runs[::2]\n",
    "        return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = WandbLogger(project=\"DACON\")\n",
    "model = LitSeg()\n",
    "data_module = SatelliteDataModule(\n",
    "    root=configs[\"data\"][\"root\"], \n",
    "    batch_size=configs[\"data\"][\"batch_size\"]\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=\"16-mixed\",\n",
    "    logger=logger, \n",
    "    max_epochs=300, \n",
    ")\n",
    "trainer.fit(model=model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitSeg().load_from_checkpoint(\"DACON/...\")\n",
    "trainer.test(model=model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture](https://github.com/silverstar0727/artifacts/blob/main/dacon-buliding-wandb.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
